scale_colour_viridis_c()
trump_tweets %>%
mutate(sources = fct_lump(source, n = 5)) %>%
count(sources) %>%
ggplot() + aes(fct_reorder(sources,n), n, fill = sources) + geom_col() + coord_flip()+
geom_text(aes(label = n, color =sources), nudge_y = 400) + scale_fill_viridis_d() +
scale_colour_viridis_b()
trump_tweets %>%
mutate(sources = fct_lump(source, n = 5)) %>%
count(sources) %>%
ggplot() + aes(fct_reorder(sources,n), n, fill = sources) + geom_col() + coord_flip()+
geom_text(aes(label = n, color =sources), nudge_y = 400) + scale_fill_viridis_d() +
scale_colour_viridis_c()
trump_tweets %>%
mutate(sources = fct_lump(source, n = 5)) %>%
count(sources) %>%
ggplot() + aes(fct_reorder(sources,n), n, fill = sources) + geom_col() + coord_flip()+
geom_text(aes(label = n, color =sources), nudge_y = 400) + scale_fill_viridis_d()
trump_tweets %>%
mutate(sources = fct_lump(source, n = 5)) %>%
count(sources) %>%
ggplot() + aes(fct_reorder(sources,n), n, fill = sources) + geom_col() + coord_flip()+
geom_text(aes(label = n, color =n), nudge_y = 400) + scale_fill_viridis_d()
trump_tweets %>%
mutate(sources = fct_lump(source, n = 5)) %>%
count(sources) %>%
ggplot() + aes(fct_reorder(sources,n), n, fill = sources) + geom_col() + coord_flip()+
geom_text(aes(label = n), nudge_y = 400) + scale_fill_viridis_d()
trump_tweets %>%
mutate(sources = fct_lump(source, n = 5)) %>%
count(sources) %>%
ggplot() + aes(fct_reorder(sources,n), n, fill = sources) + geom_col() + coord_flip()+
geom_text(aes(label = n), nudge_y = 400) + scale_fill_viridis_d(guide = NULL)
trump_tweets %>%
mutate(sources = fct_lump(source, n = 5)) %>%
count(sources) %>%
ggplot() + aes(fct_reorder(sources,n), n, fill = sources) + geom_col() + coord_flip()+
geom_text(aes(label = n), nudge_y = 400) + scale_fill_viridis_d(guide = NULL) + labs( y = "")
trump_tweets %>%
mutate(sources = fct_lump(source, n = 5)) %>%
count(sources) %>%
ggplot() + aes(fct_reorder(sources,n), n, fill = sources) + geom_col() + coord_flip()+
geom_text(aes(label = n), nudge_y = 400) + scale_fill_viridis_d(guide = NULL) + labs( y = " ")
trump_tweets %>%
mutate(sources = fct_lump(source, n = 5)) %>%
count(sources) %>%
ggplot() + aes(fct_reorder(sources,n), n, fill = sources) + geom_col() + coord_flip()+
geom_text(aes(label = n), nudge_y = 400) + scale_fill_viridis_d(guide = NULL) + labs( x = "")
trump_tweets
trump_tweets %>%
extract(source, "source", "Twitter for (.*)")
trump_tweets %>%
extract(source, "source", "Twitter for (.*)") %>%
filter(source %in% c("Android", "iPhone"))
trump_tweets %>%
extract(source, "source", "Twitter for (.*)") %>%
filter(source %in% c("Android", "iPhone") &
created_at >= ymd("2015-06-17"))
trump_tweets %>%
extract(source, "source", "Twitter for (.*)") %>%
filter(source %in% c("Android", "iPhone") &
created_at >= ymd("2015-06-17") &
created_at < ymd("2016-11-08"))
trump_tweets %>%
extract(source, "source", "Twitter for (.*)") %>%
filter(source %in% c("Android", "iPhone") &
created_at >= ymd("2015-06-17") &
created_at < ymd("2016-11-08")) %>%
filter(!is_retweet)
trump_tweets %>%
extract(source, "source", "Twitter for (.*)") %>%
filter(source %in% c("Android", "iPhone") &
created_at >= ymd("2015-06-17") &
created_at < ymd("2016-11-08")) %>%
filter(!is_retweet) %>%
arrange(created_at)
trump_tweets %>%
extract(source, "source", "Twitter for (.*)") %>%
filter(source %in% c("Android", "iPhone") &
created_at >= ymd("2015-06-17") &
created_at < ymd("2016-11-08")) %>%
filter(!is_retweet) %>%
arrange(created_at) %>%
as_tibble()
trump_tweets %>%
extract(source, "source", "Twitter for (.*)") %>%
filter(source %in% c("Android", "iPhone") &
created_at >= ymd("2015-06-17") &
created_at < ymd("2016-11-08")) %>%
filter(!is_retweet) %>%
arrange(created_at) %>%
as_tibble() -> campaign_tweets
campaign_tweets
campaign_tweets %>%
mutate(hour = hour(with_tz(created_at, "EST")))
campaign_tweets %>%
mutate(hour = hour(with_tz(created_at, "EST"))) %>%
count(source, hour)
campaign_tweets %>%
mutate(hour = hour(with_tz(created_at, "EST"))) %>%
count(source, hour) %>%
group_by(source)
campaign_tweets %>%
mutate(hour = hour(with_tz(created_at, "EST"))) %>%
count(source, hour) %>%
group_by(source) %>%
mutate(percent = n)
campaign_tweets %>%
mutate(hour = hour(with_tz(created_at, "EST"))) %>%
count(source, hour) %>%
group_by(source) %>%
mutate(percent = n / sum(n))
campaign_tweets %>%
mutate(hour = hour(with_tz(created_at, "EST"))) %>%
count(source, hour) %>%
group_by(source) %>%
mutate(percent = n / sum(n)) %>%
ungroup()
campaign_tweets %>%
mutate(hour = hour(with_tz(created_at, "EST"))) %>%
count(source, hour) %>%
group_by(source) %>%
mutate(percent = n / sum(n)) %>%
ungroup() %>%
ggplot(aes(hour, percent, color = source)) +
geom_line()
campaign_tweets %>%
mutate(hour = hour(with_tz(created_at, "EST"))) %>%
count(source, hour) %>%
group_by(source) %>%
mutate(percent = n / sum(n)) %>%
ungroup() %>%
ggplot(aes(hour, percent, color = source)) +
geom_line() +
geom_point()
campaign_tweets %>%
mutate(hour = hour(with_tz(created_at, "EST"))) %>%
count(source, hour) %>%
group_by(source) %>%
mutate(percent = n / sum(n)) %>%
ungroup() %>%
ggplot(aes(hour, percent, color = source)) +
geom_line() +
geom_point() +
scale_y_continious(labels = percent_format()) +
labs(x = "Hour of day (EST)", y =)
campaign_tweets %>%
mutate(hour = hour(with_tz(created_at, "EST"))) %>%
count(source, hour) %>%
group_by(source) %>%
mutate(percent = n / sum(n)) %>%
ungroup() %>%
ggplot(aes(hour, percent, color = source)) +
geom_line() +
geom_point() +
scale_y_continious(labels = percent_format()) +
labs(x = "Hour of day (EST)", y = "% of tweets", color = "")
campaign_tweets %>%
mutate(hour = hour(with_tz(created_at, "EST"))) %>%
count(source, hour) %>%
group_by(source) %>%
mutate(percent = n / sum(n)) %>%
ungroup() %>%
ggplot(aes(hour, percent, color = source)) +
geom_line() +
geom_point() +
scale_y_continious(labels = percent_format()) +
labs(x = "Hour of day (EST)", y = "% of tweets")
campaign_tweets %>%
mutate(hour = hour(with_tz(created_at, "EST"))) %>%
count(source, hour) %>%
group_by(source) %>%
mutate(percent = n / sum(n)) %>%
ungroup() %>%
ggplot(aes(hour, percent, color = source)) +
geom_line() +
geom_point() +
scale_y_continious(labels = percent_format())
campaign_tweets %>%
mutate(hour = hour(with_tz(created_at, "EST"))) %>%
count(source, hour) %>%
group_by(source) %>%
mutate(percent = n / sum(n)) %>%
ungroup() %>%
ggplot(aes(hour, percent, color = source)) +
geom_line() +
geom_point() +
scale_y_continuous() +
labs(x = "Hour of day (EST)", y = "% of tweets")
campaign_tweets %>%
mutate(hour = hour(with_tz(created_at, "EST"))) %>%
count(source, hour) %>%
group_by(source) %>%
mutate(percent = n / sum(n)) %>%
ungroup() %>%
ggplot(aes(hour, percent, color = source)) +
geom_line() +
geom_point() +
scale_y_continuous(labels = scales::percent()) +
labs(x = "Hour of day (EST)", y = "% of tweets")
campaign_tweets %>%
mutate(hour = hour(with_tz(created_at, "EST"))) %>%
count(source, hour) %>%
group_by(source) %>%
mutate(percent = n / sum(n)) %>%
ungroup() %>%
ggplot(aes(hour, percent, color = source)) +
geom_line() +
geom_point() +
scale_y_continuous(labels = scales::percent_format()) +
labs(x = "Hour of day (EST)", y = "% of tweets")
library(tidytext)
poem <- c("Roses are red,", "Violets are blue,",
"Sugar is sweet,", "And so are you.")
example <- tibble(line = c(1,2,3,4), text= poem)
example
example %>%
unnest_tokens(word, text)
unnest_tokens
example %>%
unnest_tokens(word, text)
example %>%
unnest_tokens(word, text)
campaign_tweets
campaign_tweets[i,]
campaign_tweets[3008,]
campaign_tweets[3008,]
campaign_tweets[3008,] %>%
mutate(text = str_replace_all(text, links))
links <- "https://t.co/[A-Z-a-z\\d]+|&amp;"
campaign_tweets[3008,] %>%
mutate(text = str_replace_all(text, links))
campaign_tweets[3008,] %>%
mutate(text = str_replace_all(text, links,""))
campaign_tweets[3008,] %>%
select(text)
campaign_tweets[3008,] %>%
select(text) %>% pull()
campaign_tweets[3008,] %>%
mutate(text = str_replace_all(text, links,""))
campaign_tweets[3008,] %>%
mutate(text = str_replace_all(text, links,"")) %>%
pull(text)
campaign_tweets[3008,] %>%
mutate(text = str_replace_all(text, links,""))
campaign_tweets %>%
mutate(text = str_remove_all(text, links, ""))
campaign_tweets %>%
mutate(text = str_replace_all(text, links, ""))
campaign_tweets %>%
mutate(text = str_replace_all(text, links, "")) %>%
unnest_tokens()
campaign_tweets %>%
mutate(text = str_replace_all(text, links, "")) %>%
unnest_tokens(word,text)
campaign_tweets %>%
mutate(text = str_replace_all(text, links, "")) %>%
unnest_tokens(word,text) -> tweet_words
tweet_words
tweet_words %>%
count(word)
tweet_words %>%
count(word) %>%
arrange(desc(n))
tweet_words %>%
anti_join(stop_words, by = "word")
tweet_words %>%
anti_join(stop_words, by = "word") %>%
count(word) %>%
arrange(desc(n))
styler:::style_selection()
tweet_words %>%
anti_join(stop_words, by = "word") %>%
count(word) %>%
arrange(desc(n))
tweet_words %>%
anti_join(stop_words, by = "word") %>%
count(word) %>%
arrange(desc(n))
tweet_words %>%
anti_join(stop_words, by = "word") %>%
count(word) %>%
arrange(desc(n))
tweet_words %>%
anti_join(stop_words, by = "word") %>%
count(word) %>%
arrange(desc(n))
tweet_words %>%
anti_join(stop_words, by = "word") %>%
count(word) %>%
arrange(desc(n))
tweet_words %>%
anti_join(stop_words, by = "word") %>%
count(word) %>%
arrange(desc(n)) %>%
filter(str_detect(word, "^\\d+$"))
tweet_words %>%
anti_join(stop_words, by = "word") %>%
count(word) %>%
arrange(desc(n)) %>%
filter(!str_detect(word, "^\\d+$"))
tweet_words %>%
anti_join(stop_words, by = "word") %>%
count(word) %>%
arrange(desc(n)) %>%
filter(str_detect(word, "^\\d+$"))
tweet_words %>%
anti_join(stop_words, by = "word") %>%
count(word) %>%
arrange(desc(n)) %>%
filter(!str_detect(word, "^\\d+$"))
tweet_words %>%
anti_join(stop_words, by = "word") %>%
count(word) %>%
arrange(desc(n)) %>%
filter(!str_detect(word, "^\\d+$"))
tweet_words %>%
anti_join(stop_words, by = "word") %>%
count(word) %>%
arrange(desc(n)) %>%
filter(!str_detect(word, "^\\d+$"))
tweet_words %>%
anti_join(stop_words, by = "word") %>%
count(word) %>%
arrange(desc(n)) %>%
filter(!str_detect(word, "^\\d+$"))
campaign_tweets
tweet_words
tweet_words %>%
count(word, source)
tweet_words %>%
count(word, source) %>%
pivot_wider(names_from = source, values_from = n)
tweet_words %>%
count(word, source) %>%
pivot_wider(names_from = source, values_from = n) %>%
add_count(Android,iPhone)
tweet_words %>%
count(word, source) %>%
pivot_wider(names_from = source, values_from = n) %>%
add_count(Android)
tweet_words %>%
count(word, source) %>%
pivot_wider(names_from = source, values_from = n)
?pivot_wider
tweet_words %>%
count(word, source) %>%
pivot_wider(names_from = source, values_from = n, values_fill = 0)
tweet_words %>%
count(word, source) %>%
pivot_wider(names_from = source, values_from = n, values_fill = 0) %>%
mutate(p_a = Android / sum(Android),
p_i = iPhone / sum(iPhone))
tweet_words %>%
count(word, source) %>%
pivot_wider(names_from = source, values_from = n, values_fill = 0) %>%
mutate(p_a = Android / sum(Android),
p_i = iPhone / sum(iPhone)) %>%
filter(Android + iPhone >= 100)
tweet_words %>%
count(word, source) %>%
pivot_wider(names_from = source, values_from = n, values_fill = 0) %>%
mutate(p_a = Android / sum(Android) * 100,
p_i = iPhone / sum(iPhone) * 100) %>%
filter(Android + iPhone >= 100)
tweet_words %>%
count(word, source) %>%
pivot_wider(names_from = source, values_from = n, values_fill = 0) %>%
mutate(p_a = Android / sum(Android) * 100,
p_i = iPhone / sum(iPhone) * 100) %>%
filter(Android + iPhone >= 100, percent_diff = p_a - p_i)
tweet_words %>%
count(word, source) %>%
pivot_wider(names_from = source, values_from = n, values_fill = 0) %>%
mutate(p_a = Android / sum(Android) * 100,
p_i = iPhone / sum(iPhone) * 100, percent_diff = p_a - p_i) %>%
filter(Android + iPhone >= 100)
tweet_words %>%
count(word, source) %>%
pivot_wider(names_from = source, values_from = n, values_fill = 0) %>%
mutate(p_a = Android / sum(Android) * 100,
p_i = iPhone / sum(iPhone) * 100, percent_diff = p_a - p_i) %>%
filter(Android + iPhone >= 100) %>%
arrange(-percet_diff)
tweet_words %>%
count(word, source) %>%
pivot_wider(names_from = source, values_from = n, values_fill = 0) %>%
mutate(p_a = Android / sum(Android) * 100,
p_i = iPhone / sum(iPhone) * 100, percent_diff = p_a - p_i) %>%
filter(Android + iPhone >= 100) %>%
arrange(-percent_diff)
tweet_words %>%
count(word, source) %>%
pivot_wider(names_from = source, values_from = n, values_fill = 0) %>%
mutate(p_a = Android / sum(Android) * 100,
p_i = iPhone / sum(iPhone) * 100, percent_diff = p_a - p_i) %>%
filter(Android + iPhone >= 100) %>%
arrange(-percent_diff) %>%
anti_join(stop_words, by = "word")
tweet_words %>%
count(word, source) %>%
pivot_wider(names_from = source, values_from = n, values_fill = 0) %>%
mutate(p_a = Android / sum(Android) * 100,
p_i = iPhone / sum(iPhone) * 100, percent_diff = p_a - p_i) %>%
filter(Android + iPhone >= 100) %>%
arrange(-percent_diff) %>%
anti_join(stop_words, by = "word") -> android_iphone
android_iphone
android_iphone  %>%
semi_join(get_sentiments("bing"), by = "word")
get_sentiments("afinn")
install.packages("textdata")
library(textdata)
get_sentiments("afinn")
get_sentiments("afinn")
get_sentiments("nrc")
get_sentiments("nrc") %>% count(sentiment)
nrc
get_sentiments("nrc")
tweet_words
tweet_words %>%
inner_join(nrc, by= "word", relationship = "many-to-kmany")
tweet_words %>%
inner_join(get_sentiments("nrc"), by= "word", relationship = "many-to-kmany")
tweet_words %>%
inner_join(get_sentiments("nrc"), by= "word", relationship = "many-to-many")
tweet_words %>%
inner_join(get_sentiments("nrc"), by= "word", relationship = "many-to-many") %>%
select(source, word, sentiment)
tweet_words %>%
inner_join(get_sentiments("nrc"), by= "word", relationship = "many-to-many") %>%
select(source, word, sentiment)
tweet_words %>%
inner_join(get_sentiments("nrc"), by= "word", relationship = "many-to-many") %>%
select(source, word, sentiment) %>%
count(sentiments)
tweet_words
tweet_words %>%
left_join(get_sentiments("nrc"), by = "word", relationship = "many-to-many")
tweet_words %>%
left_join(get_sentiments("nrc"), by = "word", relationship = "many-to-many") %>%
count(source, sentiment)
tweet_words %>%
left_join(get_sentiments("nrc"), by = "word", relationship = "many-to-many") %>%
count(source, sentiment) %>%
pivot_wider(names_from = "source", values_from = "n")
tweet_words %>%
left_join(get_sentiments("nrc"), by = "word", relationship = "many-to-many") %>%
count(source, sentiment) %>%
pivot_wider(names_from = "source", values_from = "n") -> sentiment_counts
sentiment_counts
sentiment_counts %>%
mutate(p_a = Android / sum(Android),
p_i = iPhone/sum(iPhone))
sentiment_counts %>%
mutate(p_a = Android / sum(Android),
p_i = iPhone/sum(iPhone),
per_diff = p_a - p_i) %>%
arrange(-pc_diff)
source("~/.active-rstudio-document", echo=TRUE)
install.packages("textdata")
sentiment_counts %>%
mutate(p_a = Android / sum(Android),
p_i = iPhone/sum(iPhone),
per_diff = p_a - p_i) %>%
arrange(-pc_diff)
get_sentiments("nrc") %>% count(sentiment)
tweet_words %>%
inner_join(get_sentiments("nrc"), by= "word", relationship = "many-to-many") %>%
select(source, word, sentiment)
tweet_words %>%
left_join(get_sentiments("nrc"), by = "word", relationship = "many-to-many") %>%
count(source, sentiment) %>%
pivot_wider(names_from = "source", values_from = "n") -> sentiment_counts
sentiment_counts %>%
mutate(p_a = Android / sum(Android),
p_i = iPhone/sum(iPhone),
per_diff = p_a - p_i) %>%
arrange(-pc_diff)
sentiment_counts %>%
mutate(p_a = Android / sum(Android),
p_i = iPhone/sum(iPhone),
per_diff = p_a - p_i) %>%
arrange(-per_diff)
palmerpenguins::penguins
palmerpenguins::penguins %>%
ggplot() + aes(x = sex) + geom_bar()
palmerpenguins::penguins %>%
ggplot() + aes(x = sex) + geom_bar(position = "stacked")
?geom_bar
palmerpenguins::penguins %>%
ggplot() + aes(x = sex) + stat_count(position = "stacked")
palmerpenguins::penguins %>%
ggplot() + aes(x = sex) + stat_count(position = "stack")
palmerpenguins::penguins %>%
ggplot() + aes(x = sex) + geom_col(position = "stack")
palmerpenguins::penguins %>%
ggplot() + aes(x = sex) + geom_bar(position = "stack")
palmerpenguins::penguins %>%
ggplot() + aes(x = sex, fill =sex) + geom_bar(position = "stack")
palmerpenguins::penguins %>%
ggplot() + aes(x = sex, fill =sex) + geom_bar(position = "identity")
palmerpenguins::penguins %>%
ggplot() + aes(x = sex, fill =sex) + geom_bar(position = "stack")
palmerpenguins::penguins %>%
ggplot() + aes(x = sex, fill =sex) + geom_bar(position = "stack")
palmerpenguins::penguins %>%
ggplot() + aes(x = sex, fill =sex) + geom_bar(position = "stack", stat="identity")
palmerpenguins::penguins %>%
ggplot() + aes(x = sex, y =value) + geom_bar(position = "stack", stat="identity")
palmerpenguins::penguins %>%
ggplot() + aes(x = sex, y =value) + geom_bar(position = "stack", stat="identity")
